{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "quick-theory",
   "metadata": {},
   "source": [
    "## Selection bias and missing values with COMPAS data\n",
    "This notebook demonstrates the effect of selection bias and missing values on fairness using COMPAS data. <br>\n",
    "In this notebook, we first import packages needed in this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "durable-alias",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"models\")\n",
    "sys.path.append(\"AIF360/\")\n",
    "import numpy as np\n",
    "from compas_model import get_distortion_compas, CompasDataset, reweight_df, get_evaluation, CompasDataset_test, CompasDataset_train, load_preproc_data_compas_test_comb\n",
    "from aif360.algorithms.preprocessing.optim_preproc import OptimPreproc\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.opt_tools import OptTools\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compound-portable",
   "metadata": {},
   "source": [
    "The function below creates a dataset with both missing values and selection bias. This processing is a combination of demo_missing_compas.ipynb and demo_sel_compas.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "homeless-china",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preproc_data_compas_train(protected_attributes=None):\n",
    "    def custom_preprocessing(df):\n",
    "        \"\"\"The custom pre-processing function is adapted from\n",
    "            https://github.com/fair-preprocessing/nips2017/blob/master/compas/code/Generate_Compas_Data.ipynb\n",
    "        \"\"\"\n",
    "\n",
    "        df = df[['age',\n",
    "                 'c_charge_degree',\n",
    "                 'race',\n",
    "                 'age_cat',\n",
    "                 'score_text',\n",
    "                 'sex',\n",
    "                 'priors_count',\n",
    "                 'days_b_screening_arrest',\n",
    "                 'decile_score',\n",
    "                 'is_recid',\n",
    "                 'two_year_recid',\n",
    "                 'length_of_stay']]\n",
    "\n",
    "        # Indices of data samples to keep\n",
    "        ix = df['days_b_screening_arrest'] <= 30\n",
    "        ix = (df['days_b_screening_arrest'] >= -30) & ix\n",
    "        ix = (df['is_recid'] != -1) & ix\n",
    "        ix = (df['c_charge_degree'] != \"O\") & ix\n",
    "        ix = (df['score_text'] != 'N/A') & ix\n",
    "        df = df.loc[ix, :]\n",
    "\n",
    "        # Restrict races to African-American and Caucasian\n",
    "        dfcut = df.loc[~df['race'].isin(\n",
    "            ['Native American', 'Hispanic', 'Asian', 'Other']), :]\n",
    "\n",
    "        # Restrict the features to use\n",
    "        dfcutQ = dfcut[['sex',\n",
    "                        'race',\n",
    "                        'age_cat',\n",
    "                        'c_charge_degree',\n",
    "                        'score_text',\n",
    "                        'priors_count',\n",
    "                        'is_recid',\n",
    "                        'two_year_recid',\n",
    "                        'length_of_stay']].copy()\n",
    "\n",
    "        # Quantize priors count between 0, 1-3, and >3\n",
    "        def quantizePrior(x):\n",
    "            if x == 0:\n",
    "                return '0'\n",
    "            elif x == 1:\n",
    "                return '1 to 3'\n",
    "            elif x == 2:\n",
    "                return 'More than 3'\n",
    "            else:\n",
    "                return 'missing'\n",
    "        # Quantize length of stay\n",
    "\n",
    "        def quantizeLOS(x):\n",
    "            if x == 0:\n",
    "                return '<week'\n",
    "            if x == 1:\n",
    "                return '<3months'\n",
    "            else:\n",
    "                return '>3 months'\n",
    "\n",
    "        # Quantize length of stay\n",
    "        def adjustAge(x):\n",
    "            if x == 1:\n",
    "                return '25 to 45'\n",
    "            elif x == 2:\n",
    "                return 'Greater than 45'\n",
    "            elif x == 0:\n",
    "                return 'Less than 25'\n",
    "        # Quantize score_text to MediumHigh\n",
    "\n",
    "        def quantizeScore(x):\n",
    "            if x == 1:\n",
    "                return 'MediumHigh'\n",
    "            else:\n",
    "                return 'Low'\n",
    "\n",
    "        def group_race(x):\n",
    "            if x == \"Caucasian\":\n",
    "                return 1.0\n",
    "            else:\n",
    "                return 0.0\n",
    "\n",
    "        dfcutQ['priors_count'] = dfcutQ['priors_count'].apply(\n",
    "            lambda x: quantizePrior(x))\n",
    "        dfcutQ['length_of_stay'] = dfcutQ['length_of_stay'].apply(\n",
    "            lambda x: quantizeLOS(x))\n",
    "        dfcutQ['score_text'] = dfcutQ['score_text'].apply(\n",
    "            lambda x: quantizeScore(x))\n",
    "        dfcutQ['age_cat'] = dfcutQ['age_cat'].apply(lambda x: adjustAge(x))\n",
    "        # Recode sex and race\n",
    "        dfcutQ['sex'] = dfcutQ['sex'].replace({'Female': 1.0, 'Male': 0.0})\n",
    "        dfcutQ['race'] = dfcutQ['race'].apply(lambda x: group_race(x))\n",
    "\n",
    "        features = ['two_year_recid', 'race',\n",
    "                    'age_cat', 'priors_count', 'c_charge_degree', 'score_text']\n",
    "        # the code below creates a dataset with selection, same approach as demo_sel_compas.ipynb\n",
    "        # Pass vallue to df\n",
    "        df = dfcutQ[features]\n",
    "        # Here, we filter out dataframe with negative outcome\n",
    "        df_neg = df.loc[df['two_year_recid'] == 1, :]\n",
    "        # df_neg_priv represents observations with negative outcome in privileged group\n",
    "        df_neg_priv = df_neg.loc[(df_neg['two_year_recid'] == 1) & (\n",
    "            df_neg['race'] == 1), :]\n",
    "        # df_neg_unpriv represents observations with negative outcome in unprivileged group\n",
    "        df_neg_unpriv = df_neg.loc[(df_neg['two_year_recid'] == 1) & (\n",
    "            df_neg['race'] == 0), :]\n",
    "        # the code below will create a biased dataset for observations with negative outcome. \n",
    "        # We randomly select observations from df_neg_unpriv and df_neg_priv to create\n",
    "        # a new dataset with selection bias \n",
    "        _, df_neg_priv_test = train_test_split(\n",
    "            df_neg_priv, test_size=500, random_state=10)\n",
    "        _, df_neg_unpriv_test = train_test_split(\n",
    "            df_neg_unpriv, test_size=950, random_state=10)\n",
    "        df_neg_test = df_neg_priv_test.append(df_neg_unpriv_test)\n",
    "        print('negative outcome, unpriv before resampling')\n",
    "        print(len(df_neg_unpriv_test.index))\n",
    "\n",
    "        print('negative outcome, priv before resampling')\n",
    "        print(len(df_neg_priv_test.index))\n",
    "        # Here, we filter out dataframe with positive outcome\n",
    "        df_pos = df.loc[df['two_year_recid'] == 0, :]\n",
    "        # df_pos_priv represents observations with positive outcome in privileged group\n",
    "        df_pos_priv = df_pos.loc[(df_pos['two_year_recid'] == 0) & (\n",
    "            df_pos['race'] == 1), :]\n",
    "        # df_pos_unpriv represents observations with positive outcome in unprivileged group\n",
    "        df_pos_unpriv = df_pos.loc[(df_pos['two_year_recid'] == 0) & (\n",
    "            df_pos['race'] == 0), :]\n",
    "        # the code below will create a biased dataset for observations with positive outcome. \n",
    "        # We randomly select observations from df_pos_unpriv and df_pos_priv to create\n",
    "        # a new dataset with selection bias.\n",
    "        _, df_pos_priv_test = train_test_split(\n",
    "            df_pos_priv, test_size=650, random_state=10)\n",
    "        _, df_pos_unpriv_test = train_test_split(\n",
    "            df_pos_unpriv, test_size=900, random_state=10)\n",
    "        df_pos_test = df_pos_priv_test.append(df_pos_unpriv_test)\n",
    "        print('positive outcome, unpriv before resampling')\n",
    "        print(len(df_pos_unpriv_test.index))\n",
    "\n",
    "        print('positive outcome, priv before resampling')\n",
    "        print(len(df_pos_priv_test.index))\n",
    "        df = df_neg_test.append(df_pos_test)\n",
    "        \n",
    "        df['mis_prob'] = 0\n",
    "        # the code below creates MAR type of missing value, the processing is the same as \n",
    "        # demo_missing_compas.ipynb\n",
    "        for index, row in df.iterrows():\n",
    "            if row['race'] != 'African-American' and row['two_year_recid']==0:\n",
    "                df.loc[index, 'mis_prob'] = 0.3\n",
    "            elif row['race'] != 'African-American':\n",
    "                df.loc[index, 'mis_prob'] = 0.1\n",
    "            else:\n",
    "                df.loc[index, 'mis_prob'] = 0.05\n",
    "        new_label = []\n",
    "        for index, row in df.iterrows():\n",
    "            if np.random.binomial(1, float(row['mis_prob']), 1)[0] == 1:\n",
    "                new_label.append('missing')\n",
    "            else:\n",
    "                new_label.append(row['priors_count'])\n",
    "        df['priors_count'] = new_label\n",
    "        print('Total number of missing values')\n",
    "        print(len(df.loc[df['priors_count'] == 'missing', :].index))\n",
    "        print('Total number of observations')\n",
    "        print(len(df.index))\n",
    "        return df\n",
    "\n",
    "    XD_features = [\n",
    "        'age_cat',\n",
    "        'c_charge_degree',\n",
    "        'priors_count',\n",
    "        'race',\n",
    "        'score_text']\n",
    "    D_features = [\n",
    "        'race'] if protected_attributes is None else protected_attributes\n",
    "    Y_features = ['two_year_recid']\n",
    "    X_features = list(set(XD_features) - set(D_features))\n",
    "    categorical_features = [\n",
    "        'age_cat',\n",
    "        'priors_count',\n",
    "        'c_charge_degree',\n",
    "        'score_text']\n",
    "\n",
    "    # privileged classes\n",
    "    all_privileged_classes = {\"sex\": [1.0],\n",
    "                              \"race\": [1.0]}\n",
    "\n",
    "    # protected attribute maps\n",
    "    all_protected_attribute_maps = {\n",
    "        \"sex\": {\n",
    "            0.0: 'Male', 1.0: 'Female'}, \"race\": {\n",
    "            1.0: 'Caucasian', 0.0: 'Not Caucasian'}}\n",
    "\n",
    "    return CompasDataset_train(\n",
    "        label_name=Y_features[0],\n",
    "        favorable_classes=[0],\n",
    "        protected_attribute_names=D_features,\n",
    "        privileged_classes=[all_privileged_classes[x] for x in D_features],\n",
    "        instance_weights_name=None,\n",
    "        categorical_features=categorical_features,\n",
    "        features_to_keep=X_features + Y_features + D_features,\n",
    "        na_values=[],\n",
    "        metadata={'label_maps': [{1.0: 'Did recid.', 0.0: 'No recid.'}],\n",
    "                  'protected_attribute_maps': [all_protected_attribute_maps[x]\n",
    "                                               for x in D_features]},\n",
    "        custom_preprocessing=custom_preprocessing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "happy-sunset",
   "metadata": {},
   "source": [
    "The code below is to load the data and run the fairness fixing algorithm proposed by Calmon et al. \\[1\\]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conscious-brand",
   "metadata": {},
   "outputs": [],
   "source": [
    "privileged_groups = [{'race': 1}]\n",
    "unprivileged_groups = [{'race': 0}]\n",
    "dataset_orig_vt = load_preproc_data_compas_test_comb(['race'])\n",
    "dataset_orig = load_preproc_data_compas_train(['race'])\n",
    "\n",
    "optim_options = {\n",
    "    \"distortion_fun\": get_distortion_compas,\n",
    "    \"epsilon\": 0.05,\n",
    "    \"clist\": [0.99, 1.99, 2.99],\n",
    "    \"dlist\": [.1, 0.05, 0]\n",
    "}\n",
    "\n",
    "dataset_orig_train, dataset_orig_vt = dataset_orig.split(\n",
    "    [0.7], shuffle=True)\n",
    "\n",
    "OP = OptimPreproc(OptTools, optim_options,\n",
    "                  unprivileged_groups=unprivileged_groups,\n",
    "                  privileged_groups=privileged_groups)\n",
    "\n",
    "OP = OP.fit(dataset_orig_train)\n",
    "\n",
    "dataset_transf_cat_test = OP.transform(dataset_orig_vt, transform_Y=True)\n",
    "dataset_transf_cat_test = dataset_orig_vt.align_datasets(\n",
    "    dataset_transf_cat_test)\n",
    "\n",
    "dataset_transf_cat_train = OP.transform(\n",
    "    dataset_orig_train, transform_Y=True)\n",
    "dataset_transf_cat_train = dataset_orig_train.align_datasets(\n",
    "    dataset_transf_cat_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spatial-emission",
   "metadata": {},
   "source": [
    "We then use the processed data to train a logistic regression classifier and validate the classifier on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinct-evanescence",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_transf = StandardScaler()\n",
    "X_train = dataset_orig_train.features\n",
    "y_train = dataset_orig_train.labels.ravel()\n",
    "\n",
    "X_test = scale_transf.fit_transform(dataset_orig_vt.features)\n",
    "\n",
    "scale_transf = StandardScaler()\n",
    "X_train = scale_transf.fit_transform(dataset_transf_cat_train.features)\n",
    "y_train = dataset_transf_cat_train.labels.ravel()\n",
    "\n",
    "X_test = scale_transf.fit_transform(dataset_transf_cat_test.features)\n",
    "\n",
    "lmod = LogisticRegression()\n",
    "lmod.fit(X_train, y_train)\n",
    "y_pred = lmod.predict(X_test)\n",
    "print('Without resampling')\n",
    "get_evaluation(dataset_orig_vt,y_pred,privileged_groups,unprivileged_groups,0,1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lined-sydney",
   "metadata": {},
   "source": [
    "In this part, we do uniform resampling. This code is very similar to the code presented in demo_sel_compas.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended-savannah",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preproc_data_compas_train(protected_attributes=None):\n",
    "    def custom_preprocessing(df):\n",
    "        \"\"\"The custom pre-processing function is adapted from\n",
    "            https://github.com/fair-preprocessing/nips2017/blob/master/compas/code/Generate_Compas_Data.ipynb\n",
    "        \"\"\"\n",
    "\n",
    "        df = df[['age',\n",
    "                 'c_charge_degree',\n",
    "                 'race',\n",
    "                 'age_cat',\n",
    "                 'score_text',\n",
    "                 'sex',\n",
    "                 'priors_count',\n",
    "                 'days_b_screening_arrest',\n",
    "                 'decile_score',\n",
    "                 'is_recid',\n",
    "                 'two_year_recid',\n",
    "                 'length_of_stay']]\n",
    "\n",
    "        # Indices of data samples to keep\n",
    "        ix = df['days_b_screening_arrest'] <= 30\n",
    "        ix = (df['days_b_screening_arrest'] >= -30) & ix\n",
    "        ix = (df['is_recid'] != -1) & ix\n",
    "        ix = (df['c_charge_degree'] != \"O\") & ix\n",
    "        ix = (df['score_text'] != 'N/A') & ix\n",
    "        df = df.loc[ix, :]\n",
    "\n",
    "        # Restrict races to African-American and Caucasian\n",
    "        dfcut = df.loc[~df['race'].isin(\n",
    "            ['Native American', 'Hispanic', 'Asian', 'Other']), :]\n",
    "\n",
    "        # Restrict the features to use\n",
    "        dfcutQ = dfcut[['sex',\n",
    "                        'race',\n",
    "                        'age_cat',\n",
    "                        'c_charge_degree',\n",
    "                        'score_text',\n",
    "                        'priors_count',\n",
    "                        'is_recid',\n",
    "                        'two_year_recid',\n",
    "                        'length_of_stay']].copy()\n",
    "\n",
    "        # Quantize priors count between 0, 1-3, and >3\n",
    "        def quantizePrior(x):\n",
    "            if x == 0:\n",
    "                return '0'\n",
    "            elif x == 1:\n",
    "                return '1 to 3'\n",
    "            elif x == 2:\n",
    "                return 'More than 3'\n",
    "            else:\n",
    "                return 'missing'\n",
    "        # Quantize length of stay\n",
    "\n",
    "        def quantizeLOS(x):\n",
    "            if x == 0:\n",
    "                return '<week'\n",
    "            if x == 1:\n",
    "                return '<3months'\n",
    "            else:\n",
    "                return '>3 months'\n",
    "\n",
    "        # Quantize length of stay\n",
    "        def adjustAge(x):\n",
    "            if x == 1:\n",
    "                return '25 to 45'\n",
    "            elif x == 2:\n",
    "                return 'Greater than 45'\n",
    "            elif x == 0:\n",
    "                return 'Less than 25'\n",
    "        # Quantize score_text to MediumHigh\n",
    "\n",
    "        def quantizeScore(x):\n",
    "            if x == 1:\n",
    "                return 'MediumHigh'\n",
    "            else:\n",
    "                return 'Low'\n",
    "\n",
    "        def group_race(x):\n",
    "            if x == \"Caucasian\":\n",
    "                return 1.0\n",
    "            else:\n",
    "                return 0.0\n",
    "\n",
    "        dfcutQ['priors_count'] = dfcutQ['priors_count'].apply(\n",
    "            lambda x: quantizePrior(x))\n",
    "        dfcutQ['length_of_stay'] = dfcutQ['length_of_stay'].apply(\n",
    "            lambda x: quantizeLOS(x))\n",
    "        dfcutQ['score_text'] = dfcutQ['score_text'].apply(\n",
    "            lambda x: quantizeScore(x))\n",
    "        dfcutQ['age_cat'] = dfcutQ['age_cat'].apply(lambda x: adjustAge(x))\n",
    "        # Recode sex and race\n",
    "        dfcutQ['sex'] = dfcutQ['sex'].replace({'Female': 1.0, 'Male': 0.0})\n",
    "        dfcutQ['race'] = dfcutQ['race'].apply(lambda x: group_race(x))\n",
    "\n",
    "        features = ['two_year_recid', 'race',\n",
    "                    'age_cat', 'priors_count', 'c_charge_degree', 'score_text']\n",
    "\n",
    "        # Pass vallue to df\n",
    "        df = dfcutQ[features]\n",
    "        # Here, we filter out dataframe with negative outcome\n",
    "        df_neg = df.loc[df['two_year_recid'] == 1, :]\n",
    "        # df_neg_priv represents observations with negative outcome in privileged group\n",
    "        df_neg_priv = df_neg.loc[(df_neg['two_year_recid'] == 1) & (\n",
    "            df_neg['race'] == 1), :]\n",
    "        # df_neg_unpriv represents observations with negative outcome in unprivileged group\n",
    "        df_neg_unpriv = df_neg.loc[(df_neg['two_year_recid'] == 1) & (\n",
    "            df_neg['race'] == 0), :]\n",
    "        # the code below will create a biased dataset for observations with negative outcome. \n",
    "        # We randomly select observations from df_neg_unpriv and df_neg_priv to create\n",
    "        # a new dataset with selection bias \n",
    "        _, df_neg_priv_test = train_test_split(\n",
    "            df_neg_priv, test_size=500, random_state=10)\n",
    "        _, df_neg_unpriv_test = train_test_split(\n",
    "            df_neg_unpriv, test_size=950, random_state=10)\n",
    "        df_neg_test = df_neg_priv_test.append(df_neg_unpriv_test)\n",
    "        print('negative outcome, unpriv before resampling')\n",
    "        print(len(df_neg_unpriv_test.index))\n",
    "\n",
    "        print('negative outcome, priv before resampling')\n",
    "        print(len(df_neg_priv_test.index))\n",
    "        # Here, we filter out dataframe with positive outcome\n",
    "        df_pos = df.loc[df['two_year_recid'] == 0, :]\n",
    "        # df_pos_priv represents observations with positive outcome in privileged group\n",
    "        df_pos_priv = df_pos.loc[(df_pos['two_year_recid'] == 0) & (\n",
    "            df_pos['race'] == 1), :]\n",
    "        # df_pos_unpriv represents observations with positive outcome in unprivileged group\n",
    "        df_pos_unpriv = df_pos.loc[(df_pos['two_year_recid'] == 0) & (\n",
    "            df_pos['race'] == 0), :]\n",
    "        # the code below will create a biased dataset for observations with positive outcome. \n",
    "        # We randomly select observations from df_pos_unpriv and df_pos_priv to create\n",
    "        # a new dataset with selection bias.\n",
    "        _, df_pos_priv_test = train_test_split(\n",
    "            df_pos_priv, test_size=650, random_state=10)\n",
    "        _, df_pos_unpriv_test = train_test_split(\n",
    "            df_pos_unpriv, test_size=900, random_state=10)\n",
    "        df_pos_test = df_pos_priv_test.append(df_pos_unpriv_test)\n",
    "        print('positive outcome, unpriv before resampling')\n",
    "        print(len(df_pos_unpriv_test.index))\n",
    "\n",
    "        print('positive outcome, priv before resampling')\n",
    "        print(len(df_pos_priv_test.index))\n",
    "        df = df_neg_test.append(df_pos_test)\n",
    "        \n",
    "        df['mis_prob'] = 0\n",
    "        for index, row in df.iterrows():\n",
    "            if row['race'] != 'African-American' and row['two_year_recid']==0:\n",
    "                df.loc[index, 'mis_prob'] = 0.3\n",
    "            elif row['race'] != 'African-American':\n",
    "                df.loc[index, 'mis_prob'] = 0.\n",
    "            else:\n",
    "                df.loc[index, 'mis_prob'] = 0.05\n",
    "        new_label = []\n",
    "        for index, row in df.iterrows():\n",
    "            if np.random.binomial(1, float(row['mis_prob']), 1)[0] == 1:\n",
    "                new_label.append('missing')\n",
    "            else:\n",
    "                new_label.append(row['priors_count'])\n",
    "        df['priors_count'] = new_label\n",
    "        print('Total number of missing values')\n",
    "        print(len(df.loc[df['priors_count'] == 'missing', :].index))\n",
    "        print('Total number of observations')\n",
    "        print(len(df.index))\n",
    "        \n",
    "        df_result = pd.DataFrame()\n",
    "        # In this part, we preform uniform resampling described in the paper so that\n",
    "        # the training data has no selection bias\n",
    "        N = len(df)\n",
    "        for i in df['two_year_recid'].unique():\n",
    "            for j in df['race'].unique():\n",
    "                orig_df = df.loc[(df['two_year_recid'] == i)\n",
    "                                 & (df['race'] == j), :]\n",
    "                # real_count is the number of observations in the original data\n",
    "                real_count = len(orig_df.index)\n",
    "                # exp_count is the expected number of obsercations given statistical independence\n",
    "                exp_count = int((len(df.loc[(df['two_year_recid'] == i), :].index) / len(\n",
    "                    df.index)) * (len(df.loc[(df['race'] == j), :].index) / len(df.index)) * N)\n",
    "                # if real_count is bigger than exp_count, we randomly drop some samples \n",
    "                if real_count >= exp_count:\n",
    "                    _, df_toapp = train_test_split(\n",
    "                        orig_df, test_size=exp_count, random_state=10)\n",
    "                # if real_count is smaller than exp_count, we bootstrap from the original data to\n",
    "                # reach statistical independence\n",
    "                else:\n",
    "                    df_toapp = resample(\n",
    "                        orig_df,\n",
    "                        replace=True,\n",
    "                        n_samples=exp_count -\n",
    "                        real_count,\n",
    "                        random_state=10)\n",
    "                    df_toapp = df_toapp.append(orig_df)\n",
    "                if len(df_result.index) == 0:\n",
    "                    df_result = df_toapp.copy()\n",
    "                else:\n",
    "                    df_result = df_result.append(df_toapp)\n",
    "        df = df_result\n",
    "        \n",
    "        return df\n",
    "\n",
    "    XD_features = [\n",
    "        'age_cat',\n",
    "        'c_charge_degree',\n",
    "        'priors_count',\n",
    "        'race',\n",
    "        'score_text']\n",
    "    D_features = [\n",
    "        'race'] if protected_attributes is None else protected_attributes\n",
    "    Y_features = ['two_year_recid']\n",
    "    X_features = list(set(XD_features) - set(D_features))\n",
    "    categorical_features = [\n",
    "        'age_cat',\n",
    "        'priors_count',\n",
    "        'c_charge_degree',\n",
    "        'score_text']\n",
    "\n",
    "    # privileged classes\n",
    "    all_privileged_classes = {\"sex\": [1.0],\n",
    "                              \"race\": [1.0]}\n",
    "\n",
    "    # protected attribute maps\n",
    "    all_protected_attribute_maps = {\n",
    "        \"sex\": {\n",
    "            0.0: 'Male', 1.0: 'Female'}, \"race\": {\n",
    "            1.0: 'Caucasian', 0.0: 'Not Caucasian'}}\n",
    "\n",
    "    return CompasDataset_train(\n",
    "        label_name=Y_features[0],\n",
    "        favorable_classes=[0],\n",
    "        protected_attribute_names=D_features,\n",
    "        privileged_classes=[all_privileged_classes[x] for x in D_features],\n",
    "        instance_weights_name=None,\n",
    "        categorical_features=categorical_features,\n",
    "        features_to_keep=X_features + Y_features + D_features,\n",
    "        na_values=[],\n",
    "        metadata={'label_maps': [{1.0: 'Did recid.', 0.0: 'No recid.'}],\n",
    "                  'protected_attribute_maps': [all_protected_attribute_maps[x]\n",
    "                                               for x in D_features]},\n",
    "        custom_preprocessing=custom_preprocessing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proprietary-budget",
   "metadata": {},
   "source": [
    "Same as the previous case, we run the processing function and run the fairness fixing algorithm proposed by Calmon et al. \\[1\\]and use the processed data to train a new logistic regression classifier and validate the classifier on the same test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closing-carroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "privileged_groups = [{'race': 1}]\n",
    "unprivileged_groups = [{'race': 0}]\n",
    "dataset_orig_vt = load_preproc_data_compas_test_comb(['race'])\n",
    "dataset_orig_train = load_preproc_data_compas_train(['race'])\n",
    "\n",
    "optim_options = {\n",
    "    \"distortion_fun\": get_distortion_compas,\n",
    "    \"epsilon\": 0.05,\n",
    "    \"clist\": [0.99, 1.99, 2.99],\n",
    "    \"dlist\": [.1, 0.05, 0]\n",
    "}\n",
    "\n",
    "OP = OptimPreproc(OptTools, optim_options,\n",
    "                  unprivileged_groups=unprivileged_groups,\n",
    "                  privileged_groups=privileged_groups)\n",
    "\n",
    "OP = OP.fit(dataset_orig_train)\n",
    "\n",
    "dataset_transf_cat_test = OP.transform(dataset_orig_vt, transform_Y=True)\n",
    "dataset_transf_cat_test = dataset_orig_vt.align_datasets(\n",
    "    dataset_transf_cat_test)\n",
    "\n",
    "dataset_transf_cat_train = OP.transform(\n",
    "    dataset_orig_train, transform_Y=True)\n",
    "dataset_transf_cat_train = dataset_orig_train.align_datasets(\n",
    "    dataset_transf_cat_train)\n",
    "scale_transf = StandardScaler()\n",
    "X_train = dataset_orig_train.features\n",
    "y_train = dataset_orig_train.labels.ravel()\n",
    "\n",
    "X_test = scale_transf.fit_transform(dataset_orig_vt.features)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "scale_transf = StandardScaler()\n",
    "dataset_orig_train.instance_weights = reweight_df(dataset_orig_train)\n",
    "scale_transf = StandardScaler()\n",
    "X_train = scale_transf.fit_transform(dataset_transf_cat_train.features)\n",
    "y_train = dataset_transf_cat_train.labels.ravel()\n",
    "X_test = scale_transf.fit_transform(dataset_transf_cat_test.features)\n",
    "lmod = LogisticRegression()\n",
    "lmod.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    sample_weight=dataset_orig_train.instance_weights)\n",
    "y_pred = lmod.predict(X_test)\n",
    "print('With uniform resampling')\n",
    "get_evaluation(dataset_orig_vt,y_pred,privileged_groups,unprivileged_groups,0,1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virgin-gravity",
   "metadata": {},
   "source": [
    "In this part, we do stratified resampling that we perform uniform resampling only on observations without missing values. This code is very similar to the code in the previous part except the resampling part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-birmingham",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preproc_data_compas_train(protected_attributes=None):\n",
    "    def custom_preprocessing(df):\n",
    "        \"\"\"The custom pre-processing function is adapted from\n",
    "            https://github.com/fair-preprocessing/nips2017/blob/master/compas/code/Generate_Compas_Data.ipynb\n",
    "        \"\"\"\n",
    "\n",
    "        df = df[['age',\n",
    "                 'c_charge_degree',\n",
    "                 'race',\n",
    "                 'age_cat',\n",
    "                 'score_text',\n",
    "                 'sex',\n",
    "                 'priors_count',\n",
    "                 'days_b_screening_arrest',\n",
    "                 'decile_score',\n",
    "                 'is_recid',\n",
    "                 'two_year_recid',\n",
    "                 'length_of_stay']]\n",
    "\n",
    "        # Indices of data samples to keep\n",
    "        ix = df['days_b_screening_arrest'] <= 30\n",
    "        ix = (df['days_b_screening_arrest'] >= -30) & ix\n",
    "        ix = (df['is_recid'] != -1) & ix\n",
    "        ix = (df['c_charge_degree'] != \"O\") & ix\n",
    "        ix = (df['score_text'] != 'N/A') & ix\n",
    "        df = df.loc[ix, :]\n",
    "\n",
    "        # Restrict races to African-American and Caucasian\n",
    "        dfcut = df.loc[~df['race'].isin(\n",
    "            ['Native American', 'Hispanic', 'Asian', 'Other']), :]\n",
    "\n",
    "        # Restrict the features to use\n",
    "        dfcutQ = dfcut[['sex',\n",
    "                        'race',\n",
    "                        'age_cat',\n",
    "                        'c_charge_degree',\n",
    "                        'score_text',\n",
    "                        'priors_count',\n",
    "                        'is_recid',\n",
    "                        'two_year_recid',\n",
    "                        'length_of_stay']].copy()\n",
    "\n",
    "        # Quantize priors count between 0, 1-3, and >3\n",
    "        def quantizePrior(x):\n",
    "            if x == 0:\n",
    "                return '0'\n",
    "            elif x == 1:\n",
    "                return '1 to 3'\n",
    "            elif x == 2:\n",
    "                return 'More than 3'\n",
    "            else:\n",
    "                return 'missing'\n",
    "        # Quantize length of stay\n",
    "\n",
    "        def quantizeLOS(x):\n",
    "            if x == 0:\n",
    "                return '<week'\n",
    "            if x == 1:\n",
    "                return '<3months'\n",
    "            else:\n",
    "                return '>3 months'\n",
    "\n",
    "        # Quantize length of stay\n",
    "        def adjustAge(x):\n",
    "            if x == 1:\n",
    "                return '25 to 45'\n",
    "            elif x == 2:\n",
    "                return 'Greater than 45'\n",
    "            elif x == 0:\n",
    "                return 'Less than 25'\n",
    "        # Quantize score_text to MediumHigh\n",
    "\n",
    "        def quantizeScore(x):\n",
    "            if x == 1:\n",
    "                return 'MediumHigh'\n",
    "            else:\n",
    "                return 'Low'\n",
    "\n",
    "        def group_race(x):\n",
    "            if x == \"Caucasian\":\n",
    "                return 1.0\n",
    "            else:\n",
    "                return 0.0\n",
    "\n",
    "        dfcutQ['priors_count'] = dfcutQ['priors_count'].apply(\n",
    "            lambda x: quantizePrior(x))\n",
    "        dfcutQ['length_of_stay'] = dfcutQ['length_of_stay'].apply(\n",
    "            lambda x: quantizeLOS(x))\n",
    "        dfcutQ['score_text'] = dfcutQ['score_text'].apply(\n",
    "            lambda x: quantizeScore(x))\n",
    "        dfcutQ['age_cat'] = dfcutQ['age_cat'].apply(lambda x: adjustAge(x))\n",
    "        # Recode sex and race\n",
    "        dfcutQ['sex'] = dfcutQ['sex'].replace({'Female': 1.0, 'Male': 0.0})\n",
    "        dfcutQ['race'] = dfcutQ['race'].apply(lambda x: group_race(x))\n",
    "\n",
    "        features = ['two_year_recid', 'race',\n",
    "                    'age_cat', 'priors_count', 'c_charge_degree', 'score_text']\n",
    "\n",
    "        # Pass vallue to df\n",
    "        df = dfcutQ[features]\n",
    "        # Here, we filter out dataframe with negative outcome\n",
    "        df_neg = df.loc[df['two_year_recid'] == 1, :]\n",
    "        # df_neg_priv represents observations with negative outcome in privileged group\n",
    "        df_neg_priv = df_neg.loc[(df_neg['two_year_recid'] == 1) & (\n",
    "            df_neg['race'] == 1), :]\n",
    "        # df_neg_unpriv represents observations with negative outcome in unprivileged group\n",
    "        df_neg_unpriv = df_neg.loc[(df_neg['two_year_recid'] == 1) & (\n",
    "            df_neg['race'] == 0), :]\n",
    "        # the code below will create a biased dataset for observations with negative outcome. \n",
    "        # We randomly select observations from df_neg_unpriv and df_neg_priv to create\n",
    "        # a new dataset with selection bias \n",
    "        _, df_neg_priv_test = train_test_split(\n",
    "            df_neg_priv, test_size=500, random_state=10)\n",
    "        _, df_neg_unpriv_test = train_test_split(\n",
    "            df_neg_unpriv, test_size=950, random_state=10)\n",
    "        df_neg_test = df_neg_priv_test.append(df_neg_unpriv_test)\n",
    "        print('negative outcome, unpriv before resampling')\n",
    "        print(len(df_neg_unpriv_test.index))\n",
    "\n",
    "        print('negative outcome, priv before resampling')\n",
    "        print(len(df_neg_priv_test.index))\n",
    "        # Here, we filter out dataframe with positive outcome\n",
    "        df_pos = df.loc[df['two_year_recid'] == 0, :]\n",
    "        # df_pos_priv represents observations with positive outcome in privileged group\n",
    "        df_pos_priv = df_pos.loc[(df_pos['two_year_recid'] == 0) & (\n",
    "            df_pos['race'] == 1), :]\n",
    "        # df_pos_unpriv represents observations with positive outcome in unprivileged group\n",
    "        df_pos_unpriv = df_pos.loc[(df_pos['two_year_recid'] == 0) & (\n",
    "            df_pos['race'] == 0), :]\n",
    "        # the code below will create a biased dataset for observations with positive outcome. \n",
    "        # We randomly select observations from df_pos_unpriv and df_pos_priv to create\n",
    "        # a new dataset with selection bias.\n",
    "        _, df_pos_priv_test = train_test_split(\n",
    "            df_pos_priv, test_size=650, random_state=10)\n",
    "        _, df_pos_unpriv_test = train_test_split(\n",
    "            df_pos_unpriv, test_size=900, random_state=10)\n",
    "        df_pos_test = df_pos_priv_test.append(df_pos_unpriv_test)\n",
    "        print('positive outcome, unpriv before resampling')\n",
    "        print(len(df_pos_unpriv_test.index))\n",
    "\n",
    "        print('positive outcome, priv before resampling')\n",
    "        print(len(df_pos_priv_test.index))\n",
    "        df = df_neg_test.append(df_pos_test)\n",
    "        \n",
    "        df['mis_prob'] = 0\n",
    "        for index, row in df.iterrows():\n",
    "            if row['race'] != 'African-American' and row['two_year_recid']==0:\n",
    "                df.loc[index, 'mis_prob'] = 0.3\n",
    "            elif row['race'] != 'African-American':\n",
    "                df.loc[index, 'mis_prob'] = 0.1\n",
    "            else:\n",
    "                df.loc[index, 'mis_prob'] = 0.05\n",
    "        new_label = []\n",
    "        for index, row in df.iterrows():\n",
    "            if np.random.binomial(1, float(row['mis_prob']), 1)[0] == 1:\n",
    "                new_label.append('missing')\n",
    "            else:\n",
    "                new_label.append(row['priors_count'])\n",
    "        df['priors_count'] = new_label\n",
    "        print('Total number of missing values')\n",
    "        print(len(df.loc[df['priors_count'] == 'missing', :].index))\n",
    "        print('Total number of observations')\n",
    "        print(len(df.index))\n",
    "        \n",
    "        df_result = pd.DataFrame()\n",
    "        # In this part, we preform statified resampling described in the paper \n",
    "        # that we only resample from observations without missing values\n",
    "        N = len(df)\n",
    "        df_result = pd.DataFrame()\n",
    "        for i in df['two_year_recid'].unique():\n",
    "            for j in df['race'].unique():\n",
    "                orig_df = df.loc[(df['two_year_recid'] == i)\n",
    "                                 & (df['race'] == j), :]\n",
    "                # here we filter the data without missing values \n",
    "                orig_df_nomiss = df.loc[(df['two_year_recid'] == i) & (\n",
    "                    df['race'] == j) & (df['priors_count'] != 'missing'), :]\n",
    "                # real_count is the number of observations in the original data\n",
    "                real_count = len(orig_df.index)\n",
    "                # exp_count is the expected number of obsercations given statistical independence\n",
    "                exp_count = int((len(df.loc[(df['two_year_recid'] == i), :].index) / len(\n",
    "                    df.index)) * (len(df.loc[(df['race'] == j), :].index) / len(df.index)) * N)\n",
    "                # if real_count is bigger than exp_count, we randomly drop some samples \n",
    "                if real_count >= exp_count:\n",
    "                    _, df_toapp = train_test_split(\n",
    "                        orig_df, test_size=exp_count, random_state=10)\n",
    "                # this is the part that is different from uniform resampling that we resample \n",
    "                # only from observations without missing values \n",
    "                else:\n",
    "                    df_toapp = resample(\n",
    "                        orig_df_nomiss,\n",
    "                        replace=True,\n",
    "                        n_samples=exp_count -\n",
    "                        real_count,\n",
    "                        random_state=10)\n",
    "                    df_toapp = df_toapp.append(orig_df)\n",
    "                if len(df_result.index) == 0:\n",
    "                    df_result = df_toapp.copy()\n",
    "                else:\n",
    "                    df_result = df_result.append(df_toapp)\n",
    "        df = df_result\n",
    "        \n",
    "        return df\n",
    "\n",
    "    XD_features = [\n",
    "        'age_cat',\n",
    "        'c_charge_degree',\n",
    "        'priors_count',\n",
    "        'race',\n",
    "        'score_text']\n",
    "    D_features = [\n",
    "        'race'] if protected_attributes is None else protected_attributes\n",
    "    Y_features = ['two_year_recid']\n",
    "    X_features = list(set(XD_features) - set(D_features))\n",
    "    categorical_features = [\n",
    "        'age_cat',\n",
    "        'priors_count',\n",
    "        'c_charge_degree',\n",
    "        'score_text']\n",
    "\n",
    "    # privileged classes\n",
    "    all_privileged_classes = {\"sex\": [1.0],\n",
    "                              \"race\": [1.0]}\n",
    "\n",
    "    # protected attribute maps\n",
    "    all_protected_attribute_maps = {\n",
    "        \"sex\": {\n",
    "            0.0: 'Male', 1.0: 'Female'}, \"race\": {\n",
    "            1.0: 'Caucasian', 0.0: 'Not Caucasian'}}\n",
    "\n",
    "    return CompasDataset_train(\n",
    "        label_name=Y_features[0],\n",
    "        favorable_classes=[0],\n",
    "        protected_attribute_names=D_features,\n",
    "        privileged_classes=[all_privileged_classes[x] for x in D_features],\n",
    "        instance_weights_name=None,\n",
    "        categorical_features=categorical_features,\n",
    "        features_to_keep=X_features + Y_features + D_features,\n",
    "        na_values=[],\n",
    "        metadata={'label_maps': [{1.0: 'Did recid.', 0.0: 'No recid.'}],\n",
    "                  'protected_attribute_maps': [all_protected_attribute_maps[x]\n",
    "                                               for x in D_features]},\n",
    "        custom_preprocessing=custom_preprocessing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spare-playback",
   "metadata": {},
   "source": [
    "Same as the previous case, we run the processing function to get a training data using stratified resampling and run the fairness fixing algorithm proposed by Calmon et al. \\[1\\] and use the processed data to train a new logistic regression classifier and validate the classifier on the same test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valuable-button",
   "metadata": {},
   "outputs": [],
   "source": [
    "privileged_groups = [{'race': 1}]\n",
    "unprivileged_groups = [{'race': 0}]\n",
    "dataset_orig_vt = load_preproc_data_compas_test_comb(['race'])\n",
    "dataset_orig_train = load_preproc_data_compas_train(['race'])\n",
    "optim_options = {\n",
    "    \"distortion_fun\": get_distortion_compas,\n",
    "    \"epsilon\": 0.05,\n",
    "    \"clist\": [0.99, 1.99, 2.99],\n",
    "    \"dlist\": [.1, 0.05, 0]\n",
    "}\n",
    "\n",
    "OP = OptimPreproc(OptTools, optim_options,\n",
    "                  unprivileged_groups=unprivileged_groups,\n",
    "                  privileged_groups=privileged_groups)\n",
    "\n",
    "OP = OP.fit(dataset_orig_train)\n",
    "\n",
    "dataset_transf_cat_test = OP.transform(dataset_orig_vt, transform_Y=True)\n",
    "dataset_transf_cat_test = dataset_orig_vt.align_datasets(\n",
    "    dataset_transf_cat_test)\n",
    "\n",
    "dataset_transf_cat_train = OP.transform(\n",
    "    dataset_orig_train, transform_Y=True)\n",
    "dataset_transf_cat_train = dataset_orig_train.align_datasets(\n",
    "    dataset_transf_cat_train)\n",
    "scale_transf = StandardScaler()\n",
    "X_train = dataset_orig_train.features\n",
    "y_train = dataset_orig_train.labels.ravel()\n",
    "\n",
    "X_test = scale_transf.fit_transform(dataset_orig_vt.features)\n",
    "\n",
    "scale_transf = StandardScaler()\n",
    "dataset_orig_train.instance_weights = reweight_df(dataset_orig_train)\n",
    "scale_transf = StandardScaler()\n",
    "X_train = scale_transf.fit_transform(dataset_transf_cat_train.features)\n",
    "y_train = dataset_transf_cat_train.labels.ravel()\n",
    "X_test = scale_transf.fit_transform(dataset_transf_cat_test.features)\n",
    "lmod = LogisticRegression()\n",
    "lmod.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    sample_weight=dataset_orig_train.instance_weights)\n",
    "y_pred = lmod.predict(X_test)\n",
    "print('With uniform resampling')\n",
    "get_evaluation(dataset_orig_vt,y_pred,privileged_groups,unprivileged_groups,0,1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varying-dream",
   "metadata": {},
   "source": [
    "# Reference\n",
    "[1] Optimized Pre-Processing for Discrimination Prevention <br>\n",
    "Flavio Calmon, Dennis Wei, Bhanukiran Vinzamuri, Karthikeyan Natesan Ramamurthy and Kush R. Varshney.\n",
    "31st Advances in Neural Information Processing Systems (NIPS), Long Beach, CA, December 2017."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
