{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "proprietary-change",
   "metadata": {},
   "source": [
    "## Selection bias with Adult data\n",
    "This notebook demonstrates the effect of selection bias on fairness using Adult data. <br>\n",
    "In this notebook, we first import packages needed in this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fifteen-queue",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"models\")\n",
    "import numpy as np\n",
    "from adult_model import get_distortion_adult_sel, AdultDataset_test, AdultDataset_train, get_evaluation, load_preproc_data_adult_test\n",
    "from aif360.algorithms.preprocessing.optim_preproc import OptimPreproc\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.opt_tools import OptTools\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "judicial-impossible",
   "metadata": {},
   "source": [
    "The function below process data and create a dataset with selection bias. <br>\n",
    "In Adult dataset, we have sex as sensitive attribute and use age (binned into decade) and education years as features to predict if the income is above or below \\$50K pre year. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "empirical-belief",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preproc_data_adult_train(protected_attributes=None):\n",
    "    def custom_preprocessing(df):\n",
    "        \"\"\"The custom pre-processing function is adapted from\n",
    "            https://github.com/fair-preprocessing/nips2017/blob/master/Adult/code/Generate_Adult_Data.ipynb\n",
    "        \"\"\"\n",
    "        np.random.seed(1)\n",
    "        # Group age by decade\n",
    "        df['Age (decade)'] = df['age'].apply(lambda x: x // 10 * 10)\n",
    "        # df['Age (decade)'] = df['age'].apply(lambda x: np.floor(x/10.0)*10.0)\n",
    "\n",
    "        def group_edu(x):\n",
    "            if x == -1:\n",
    "                return 'missing_edu'\n",
    "            elif x <= 5:\n",
    "                return '<6'\n",
    "            elif x >= 13:\n",
    "                return '>12'\n",
    "            else:\n",
    "                return x\n",
    "\n",
    "        def age_cut(x):\n",
    "            if x >= 70:\n",
    "                return '>=70'\n",
    "            else:\n",
    "                return x\n",
    "\n",
    "        def group_race(x):\n",
    "            if x == \"White\":\n",
    "                return 1.0\n",
    "            else:\n",
    "                return 0.0\n",
    "\n",
    "        # Cluster education and age attributes.\n",
    "        # Limit education range\n",
    "        df['Education Years'] = df['education-num'].apply(\n",
    "            lambda x: group_edu(x))\n",
    "        df['Education Years'] = df['Education Years'].astype('category')\n",
    "\n",
    "        # Limit age range\n",
    "        df['Age (decade)'] = df['Age (decade)'].apply(lambda x: age_cut(x))\n",
    "\n",
    "        # Rename income variable\n",
    "        df['Income Binary'] = df['income-per-year']\n",
    "\n",
    "        # Recode sex and race\n",
    "        df['sex'] = df['sex'].replace({'Female': 0.0, 'Male': 1.0})\n",
    "        df['race'] = df['race'].apply(lambda x: group_race(x))\n",
    "        \n",
    "        # Here, we filter out dataframe with negative outcome\n",
    "        df_neg = df.loc[df['Income Binary'] == '<=50K', :]\n",
    "        # df_neg_priv represents observations with negative outcome in privileged group\n",
    "        df_neg_priv = df_neg.loc[(\n",
    "            df_neg['Income Binary'] == '<=50K') & (df_neg['sex'] == 1), :]\n",
    "        # df_neg_unpriv represents observations with negative outcome in unprivileged group\n",
    "        df_neg_unpriv = df_neg.loc[(\n",
    "            df_neg['Income Binary'] == '<=50K') & (df_neg['sex'] != 1), :]\n",
    "        # the code below will create a biased dataset for observations with negative outcome. \n",
    "        # We randomly select observations from df_neg_unpriv and df_neg_priv to create\n",
    "        # a new dataset with selection bias \n",
    "        _, df_neg_priv_test = train_test_split(\n",
    "            df_neg_priv, test_size=4650, random_state=17)\n",
    "        _, df_neg_unpriv_test = train_test_split(\n",
    "            df_neg_unpriv, test_size=2850, random_state=17)\n",
    "        df_neg_test = df_neg_priv_test.append(df_neg_unpriv_test)\n",
    "        print('negative outcome, unpriv')\n",
    "        print(len(df_neg_unpriv_test.index))\n",
    "        print('negative outcome, priv')\n",
    "        print(len(df_neg_priv_test.index))\n",
    "        \n",
    "        # Here, we filter out dataframe with positive outcome\n",
    "        df_pos = df.loc[df['Income Binary'] == '>50K', :]\n",
    "        # df_pos_priv represents observations with positive outcome in privileged group\n",
    "        df_pos_priv = df_pos.loc[(\n",
    "            df_pos['Income Binary'] == '>50K') & (df_pos['sex'] == 1), :]\n",
    "        # df_pos_unpriv represents observations with positive outcome in unprivileged group\n",
    "        df_pos_unpriv = df_pos.loc[(\n",
    "            df_pos['Income Binary'] == '>50K') & (df_pos['sex'] != 1), :]\n",
    "        # the code below will create a biased dataset for observations with positive outcome. \n",
    "        # We randomly select observations from df_pos_unpriv and df_pos_priv to create\n",
    "        # a new dataset with selection bias.\n",
    "        _, df_pos_priv_test = train_test_split(\n",
    "            df_pos_priv, test_size=1800, random_state=17)\n",
    "        _, df_pos_unpriv_test = train_test_split(\n",
    "            df_pos_unpriv, test_size=700, random_state=17)\n",
    "        df_pos_test = df_pos_priv_test.append(df_pos_unpriv_test)\n",
    "        df = df_pos_test.append(df_neg_test)\n",
    "        print('positive outcome, unpriv')\n",
    "        print(len(df_pos_unpriv_test.index))\n",
    "        print('positive outcome, priv')\n",
    "        print(len(df_pos_priv_test.index))\n",
    "        return df\n",
    "\n",
    "    XD_features = ['Age (decade)', 'Education Years', 'sex', 'race']\n",
    "    D_features = [\n",
    "        'sex',\n",
    "        'race'] if protected_attributes is None else protected_attributes\n",
    "    Y_features = ['Income Binary']\n",
    "    X_features = list(set(XD_features) - set(D_features))\n",
    "    categorical_features = ['Age (decade)', 'Education Years']\n",
    "\n",
    "    # privileged classes\n",
    "    all_privileged_classes = {\"sex\": [1.0],\n",
    "                              \"race\": [1.0]}\n",
    "\n",
    "    # protected attribute maps\n",
    "    all_protected_attribute_maps = {\"sex\": {1.0: 'Male', 0.0: 'Female'},\n",
    "                                    \"race\": {1.0: 'White', 0.0: 'Non-white'}}\n",
    "\n",
    "    return AdultDataset_train(\n",
    "        label_name=Y_features[0],\n",
    "        favorable_classes=['>50K', '>50K.'],\n",
    "        protected_attribute_names=D_features,\n",
    "        privileged_classes=[all_privileged_classes[x] for x in D_features],\n",
    "        instance_weights_name=None,\n",
    "        categorical_features=categorical_features,\n",
    "        features_to_keep=X_features + Y_features + D_features,\n",
    "        na_values=['?'],\n",
    "        metadata={'label_maps': [{1.0: '>50K', 0.0: '<=50K'}],\n",
    "                  'protected_attribute_maps': [all_protected_attribute_maps[x]\n",
    "                                               for x in D_features]},\n",
    "        custom_preprocessing=custom_preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "speaking-discipline",
   "metadata": {},
   "source": [
    "The code below is to load the data and run the fairness fixing algorithm proposed by Calmon et al. \\[1\\]. We then use the processed data to train a logistic regression classifier and validate the classifier on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "western-stomach",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative outcome, unpriv\n",
      "2850\n",
      "negative outcome, priv\n",
      "4650\n",
      "positive outcome, unpriv\n",
      "700\n",
      "positive outcome, priv\n",
      "1800\n",
      "Optimized Preprocessing: Objective converged to 0.000000\n",
      "Accuracy and fairness results before resampling\n",
      "Accuracy\n",
      "0.762238191757263\n",
      "p-rule\n",
      "0.6167885638906397\n",
      "FPR for unpriv group\n",
      "0.1624922376319603\n",
      "FNR for unpriv group\n",
      "0.43728813559322033\n",
      "FPR for priv group\n",
      "0.21041557075223571\n",
      "FNR for priv group\n",
      "0.37714987714987713\n"
     ]
    }
   ],
   "source": [
    "privileged_groups = [{'sex': 1}]\n",
    "unprivileged_groups = [{'sex': 0}]\n",
    "dataset_orig_train = load_preproc_data_adult_train(['sex'])\n",
    "dataset_orig_vt = load_preproc_data_adult_test(['sex'])\n",
    "optim_options = {\n",
    "    \"distortion_fun\": get_distortion_adult_sel,\n",
    "    \"epsilon\": 0.05,\n",
    "    \"clist\": [0.99, 1.99, 2.99],\n",
    "    \"dlist\": [.1, 0.05, 0]\n",
    "}\n",
    "\n",
    "OP = OptimPreproc(OptTools, optim_options,\n",
    "                  unprivileged_groups=unprivileged_groups,\n",
    "                  privileged_groups=privileged_groups)\n",
    "\n",
    "OP = OP.fit(dataset_orig_train)\n",
    "\n",
    "dataset_transf_cat_test = OP.transform(dataset_orig_vt, transform_Y=True)\n",
    "dataset_transf_cat_test = dataset_orig_vt.align_datasets(\n",
    "    dataset_transf_cat_test)\n",
    "\n",
    "dataset_transf_cat_train = OP.transform(\n",
    "    dataset_orig_train, transform_Y=True)\n",
    "dataset_transf_cat_train = dataset_orig_train.align_datasets(\n",
    "    dataset_transf_cat_train)\n",
    "\n",
    "scale_transf = StandardScaler()\n",
    "X_train = dataset_orig_train.features\n",
    "y_train = dataset_orig_train.labels.ravel()\n",
    "X_test = scale_transf.fit_transform(dataset_orig_vt.features)\n",
    "lmod = LogisticRegression()\n",
    "lmod.fit(X_train, y_train)\n",
    "y_pred = lmod.predict(X_test)\n",
    "print('Accuracy and fairness results before resampling')\n",
    "get_evaluation(dataset_orig_vt,y_pred,privileged_groups,unprivileged_groups,0,1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satellite-iraqi",
   "metadata": {},
   "source": [
    "The code below does uniform rasampling method on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "plastic-statement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preproc_data_adult_train_fix(protected_attributes=None):\n",
    "    def custom_preprocessing(df):\n",
    "        \"\"\"The custom pre-processing function is adapted from\n",
    "            https://github.com/fair-preprocessing/nips2017/blob/master/Adult/code/Generate_Adult_Data.ipynb\n",
    "        \"\"\"\n",
    "        np.random.seed(1)\n",
    "        # Group age by decade\n",
    "        df['Age (decade)'] = df['age'].apply(lambda x: x // 10 * 10)\n",
    "        # df['Age (decade)'] = df['age'].apply(lambda x: np.floor(x/10.0)*10.0)\n",
    "\n",
    "        def group_edu(x):\n",
    "            if x == -1:\n",
    "                return 'missing_edu'\n",
    "            elif x <= 5:\n",
    "                return '<6'\n",
    "            elif x >= 13:\n",
    "                return '>12'\n",
    "            else:\n",
    "                return x\n",
    "\n",
    "        def age_cut(x):\n",
    "            if x >= 70:\n",
    "                return '>=70'\n",
    "            else:\n",
    "                return x\n",
    "\n",
    "        def group_race(x):\n",
    "            if x == \"White\":\n",
    "                return 1.0\n",
    "            else:\n",
    "                return 0.0\n",
    "\n",
    "        # Cluster education and age attributes.\n",
    "        # Limit education range\n",
    "        df['Education Years'] = df['education-num'].apply(\n",
    "            lambda x: group_edu(x))\n",
    "        df['Education Years'] = df['Education Years'].astype('category')\n",
    "\n",
    "        # Limit age range\n",
    "        df['Age (decade)'] = df['Age (decade)'].apply(lambda x: age_cut(x))\n",
    "\n",
    "        # Rename income variable\n",
    "        df['Income Binary'] = df['income-per-year']\n",
    "\n",
    "        # Recode sex and race\n",
    "        df['sex'] = df['sex'].replace({'Female': 0.0, 'Male': 1.0})\n",
    "        df['race'] = df['race'].apply(lambda x: group_race(x))\n",
    "        # This part of the code is the same as the previous function to obtain a \n",
    "        # training data with selection bias\n",
    "        df_neg = df.loc[df['Income Binary'] == '<=50K', :]\n",
    "        df_neg_priv = df_neg.loc[(\n",
    "            df_neg['Income Binary'] == '<=50K') & (df_neg['sex'] == 1), :]\n",
    "        df_neg_unpriv = df_neg.loc[(\n",
    "            df_neg['Income Binary'] == '<=50K') & (df_neg['sex'] != 1), :]\n",
    "        _, df_neg_priv_test = train_test_split(\n",
    "            df_neg_priv, test_size=4650, random_state=17)\n",
    "        _, df_neg_unpriv_test = train_test_split(\n",
    "            df_neg_unpriv, test_size=2850, random_state=17)\n",
    "        df_neg_test = df_neg_priv_test.append(df_neg_unpriv_test)\n",
    "        print('negative outcome, unpriv')\n",
    "        print(len(df_neg_unpriv_test.index))\n",
    "        print('negative outcome, priv')\n",
    "        print(len(df_neg_priv_test.index))\n",
    "\n",
    "        df_pos = df.loc[df['Income Binary'] == '>50K', :]\n",
    "        df_pos_priv = df_pos.loc[(\n",
    "            df_pos['Income Binary'] == '>50K') & (df_pos['sex'] == 1), :]\n",
    "        df_pos_unpriv = df_pos.loc[(\n",
    "            df_pos['Income Binary'] == '>50K') & (df_pos['sex'] != 1), :]\n",
    "        _, df_pos_priv_test = train_test_split(\n",
    "            df_pos_priv, test_size=1800, random_state=17)\n",
    "        _, df_pos_unpriv_test = train_test_split(\n",
    "            df_pos_unpriv, test_size=700, random_state=17)\n",
    "        df_pos_test = df_pos_priv_test.append(df_pos_unpriv_test)\n",
    "        df = df_pos_test.append(df_neg_test)\n",
    "        print('positive outcome, unpriv')\n",
    "        print(len(df_pos_unpriv_test.index))\n",
    "        print('positive outcome, priv')\n",
    "        print(len(df_pos_priv_test.index))\n",
    "        \n",
    "        # In this part, we preform uniform resampling described in the paper so that\n",
    "        # the training data has no selection bias\n",
    "        N = len(df)\n",
    "        df_result = pd.DataFrame()\n",
    "        for i in df['Income Binary'].unique():\n",
    "            for j in df['sex'].unique():\n",
    "                orig_df = df.loc[(df['Income Binary'] == i)\n",
    "                                 & (df['sex'] == j), :]\n",
    "                # real_count is the number of observations in the original data\n",
    "                real_count = len(orig_df.index)\n",
    "                # exp_count is the expected number of obsercations given statistical independence\n",
    "                exp_count = int((len(df.loc[(df['Income Binary'] == i), :].index) / len(\n",
    "                    df.index)) * (len(df.loc[(df['sex'] == j), :].index) / len(df.index)) * N)\n",
    "                # if real_count is bigger than exp_count, we randomly drop some samples \n",
    "                if real_count >= exp_count:\n",
    "                    _, df_toapp = train_test_split(\n",
    "                        orig_df, test_size=exp_count, random_state=1)\n",
    "                # if real_count is smaller than exp_count, we bootstrap from the original data to\n",
    "                # reach statistical independence\n",
    "                else:\n",
    "                    df_toapp = resample(\n",
    "                        orig_df,\n",
    "                        replace=True,\n",
    "                        n_samples=exp_count -\n",
    "                        real_count,\n",
    "                        random_state=10)\n",
    "                    df_toapp = df_toapp.append(orig_df)\n",
    "                if len(df_result.index) == 0:\n",
    "                    df_result = df_toapp.copy()\n",
    "                else:\n",
    "                    df_result = df_result.append(df_toapp)\n",
    "        df = df_result\n",
    "        \n",
    "        return df\n",
    "\n",
    "    XD_features = ['Age (decade)', 'Education Years', 'sex', 'race']\n",
    "    D_features = [\n",
    "        'sex',\n",
    "        'race'] if protected_attributes is None else protected_attributes\n",
    "    Y_features = ['Income Binary']\n",
    "    X_features = list(set(XD_features) - set(D_features))\n",
    "    categorical_features = ['Age (decade)', 'Education Years']\n",
    "\n",
    "    # privileged classes\n",
    "    all_privileged_classes = {\"sex\": [1.0],\n",
    "                              \"race\": [1.0]}\n",
    "\n",
    "    # protected attribute maps\n",
    "    all_protected_attribute_maps = {\"sex\": {1.0: 'Male', 0.0: 'Female'},\n",
    "                                    \"race\": {1.0: 'White', 0.0: 'Non-white'}}\n",
    "\n",
    "    return AdultDataset_train(\n",
    "        label_name=Y_features[0],\n",
    "        favorable_classes=['>50K', '>50K.'],\n",
    "        protected_attribute_names=D_features,\n",
    "        privileged_classes=[all_privileged_classes[x] for x in D_features],\n",
    "        instance_weights_name=None,\n",
    "        categorical_features=categorical_features,\n",
    "        features_to_keep=X_features + Y_features + D_features,\n",
    "        na_values=['?'],\n",
    "        metadata={'label_maps': [{1.0: '>50K', 0.0: '<=50K'}],\n",
    "                  'protected_attribute_maps': [all_protected_attribute_maps[x]\n",
    "                                               for x in D_features]},\n",
    "        custom_preprocessing=custom_preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conceptual-commodity",
   "metadata": {},
   "source": [
    "We load the data after resampling and run the fairness fixing algorithm proposed by Calmon et al. We then use the processed data to train a new logistic regression classifier and validate the classifier on the same test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "unlimited-advice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative outcome, unpriv\n",
      "2850\n",
      "negative outcome, priv\n",
      "4650\n",
      "positive outcome, unpriv\n",
      "700\n",
      "positive outcome, priv\n",
      "1800\n",
      "Optimized Preprocessing: Objective converged to 0.000000\n",
      "Accuracy and fairness results after resampling\n",
      "Accuracy\n",
      "0.751305202383146\n",
      "p-rule\n",
      "0.7782643569409041\n",
      "FPR for unpriv group\n",
      "0.2121713930863175\n",
      "FNR for unpriv group\n",
      "0.36949152542372876\n",
      "FPR for priv group\n",
      "0.20686480799579166\n",
      "FNR for priv group\n",
      "0.3786855036855037\n"
     ]
    }
   ],
   "source": [
    "privileged_groups = [{'sex': 1}]\n",
    "unprivileged_groups = [{'sex': 0}]\n",
    "dataset_orig_train = load_preproc_data_adult_train_fix(['sex'])\n",
    "dataset_orig_vt = load_preproc_data_adult_test(['sex'])\n",
    "optim_options = {\n",
    "    \"distortion_fun\": get_distortion_adult_sel,\n",
    "    \"epsilon\": 0.05,\n",
    "    \"clist\": [0.99, 1.99, 2.99],\n",
    "    \"dlist\": [.1, 0.05, 0]\n",
    "}\n",
    "\n",
    "OP = OptimPreproc(OptTools, optim_options,\n",
    "                  unprivileged_groups=unprivileged_groups,\n",
    "                  privileged_groups=privileged_groups)\n",
    "\n",
    "OP = OP.fit(dataset_orig_train)\n",
    "\n",
    "dataset_transf_cat_test = OP.transform(dataset_orig_vt, transform_Y=True)\n",
    "dataset_transf_cat_test = dataset_orig_vt.align_datasets(\n",
    "    dataset_transf_cat_test)\n",
    "\n",
    "dataset_transf_cat_train = OP.transform(\n",
    "    dataset_orig_train, transform_Y=True)\n",
    "dataset_transf_cat_train = dataset_orig_train.align_datasets(\n",
    "    dataset_transf_cat_train)\n",
    "\n",
    "scale_transf = StandardScaler()\n",
    "X_train = dataset_orig_train.features\n",
    "y_train = dataset_orig_train.labels.ravel()\n",
    "X_test = scale_transf.fit_transform(dataset_orig_vt.features)\n",
    "lmod = LogisticRegression()\n",
    "lmod.fit(X_train, y_train)\n",
    "y_pred = lmod.predict(X_test)\n",
    "print('Accuracy and fairness results after resampling')\n",
    "get_evaluation(dataset_orig_vt,y_pred,privileged_groups,unprivileged_groups,0,1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cultural-disposal",
   "metadata": {},
   "source": [
    "By comparing the two results, the fairness scores increase with a small tradeoff in accuracy (about 1\\% decrease in accuracy) <br>\n",
    "# Reference\n",
    "[1] Optimized Pre-Processing for Discrimination Prevention <br>\n",
    "Flavio Calmon, Dennis Wei, Bhanukiran Vinzamuri, Karthikeyan Natesan Ramamurthy and Kush R. Varshney.\n",
    "31st Advances in Neural Information Processing Systems (NIPS), Long Beach, CA, December 2017."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
