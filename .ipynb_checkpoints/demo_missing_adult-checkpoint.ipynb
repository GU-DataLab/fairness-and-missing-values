{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "several-official",
   "metadata": {},
   "source": [
    "## Missing values with Adult data\n",
    "This notebook demonstrates the effect of MAR and MNAR missing values on fairness using Adult data. <br>\n",
    "In this notebook, we first import packages needed in this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "exclusive-delhi",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"models\")\n",
    "import numpy as np\n",
    "from adult_model import get_distortion_adult, AdultDataset, reweight_df, get_evaluation\n",
    "from aif360.algorithms.preprocessing.optim_preproc import OptimPreproc\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.opt_tools import OptTools\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saving-broadcast",
   "metadata": {},
   "source": [
    "The function below process data and create missing values in the dataset. <br>\n",
    "In Adult dataset, we have sex as sensitive attribute and use age (binned into decade) and education years as features to predict if the income is above or below \\$50K pre year. <br>\n",
    "In this dataset, we create missing values in the feature \"Education Years\" with MNAR and MAR type of missing values. In the function below, the missing value mechanism is MNAR that the missing values depends on the feature itself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "knowing-bosnia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preproc_data_adult(protected_attributes=None):\n",
    "    def custom_preprocessing(df):\n",
    "        \"\"\"The custom pre-processing function is adapted from\n",
    "            https://github.com/fair-preprocessing/nips2017/blob/master/Adult/code/Generate_Adult_Data.ipynb\n",
    "        \"\"\"\n",
    "        np.random.seed(1)\n",
    "        # Group age by decade\n",
    "        df['Age (decade)'] = df['age'].apply(lambda x: x // 10 * 10)\n",
    "        def group_edu(x):\n",
    "            if x == -1:\n",
    "                return 'missing_edu'\n",
    "            elif x <= 5:\n",
    "                return '<6'\n",
    "            elif x >= 13:\n",
    "                return '>12'\n",
    "            else:\n",
    "                return x\n",
    "\n",
    "        def age_cut(x):\n",
    "            if x >= 70:\n",
    "                return '>=70'\n",
    "            else:\n",
    "                return x\n",
    "\n",
    "        def group_race(x):\n",
    "            if x == \"White\":\n",
    "                return 1.0\n",
    "            else:\n",
    "                return 0.0\n",
    "\n",
    "        # Cluster education and age attributes.\n",
    "        # Limit education range\n",
    "        df['Education Years'] = df['education-num'].apply(\n",
    "            lambda x: group_edu(x))\n",
    "        df['Education Years'] = df['Education Years'].astype('category')\n",
    "\n",
    "        # Limit age range\n",
    "        df['Age (decade)'] = df['Age (decade)'].apply(lambda x: age_cut(x))\n",
    "\n",
    "        # Rename income variable\n",
    "        df['Income Binary'] = df['income-per-year']\n",
    "\n",
    "        # Recode sex and race\n",
    "        df['sex'] = df['sex'].replace({'Female': 0.0, 'Male': 1.0})\n",
    "        df['race'] = df['race'].apply(lambda x: group_race(x))\n",
    "\n",
    "        # Here we define a column called mis_prob to assign the probability of each observation \n",
    "        # being missed\n",
    "        df['mis_prob'] = 0\n",
    "        for index, row in df.iterrows():\n",
    "            # Here, the probability of missing values in Education Years depends on sex and \n",
    "            # Education Years, so in this case the missing values are under MNAR\n",
    "            # To change the distribution of missing values, we can change the probability here\n",
    "            if row['sex']==0 and row['Education Years'] =='>12':\n",
    "                df.loc[index,'mis_prob'] = 0.65\n",
    "            elif row['sex']==1 and row['Education Years'] =='=8':\n",
    "                df.loc[index,'mis_prob'] = 0.15\n",
    "            else:\n",
    "                df.loc[index,'mis_prob'] = 0.1\n",
    "        new_label = []\n",
    "        for index, row in df.iterrows():\n",
    "            if np.random.binomial(1, float(row['mis_prob']), 1)[0] == 1:\n",
    "                new_label.append('missing_edu')\n",
    "            else:\n",
    "                new_label.append(row['Education Years'])\n",
    "        df['Education Years'] = new_label\n",
    "        print('Number of missing values')\n",
    "        print(len(df.loc[df['Education Years'] == 'missing_edu', :]))\n",
    "        print('Total number of observations')\n",
    "        print(len(df))\n",
    "        return df\n",
    "\n",
    "    XD_features = ['Age (decade)', 'Education Years', 'sex']\n",
    "    D_features = [\n",
    "        'sex'] if protected_attributes is None else protected_attributes\n",
    "    Y_features = ['Income Binary']\n",
    "    X_features = list(set(XD_features) - set(D_features))\n",
    "    categorical_features = ['Age (decade)', 'Education Years']\n",
    "    all_privileged_classes = {\"sex\": [1.0]}\n",
    "    all_protected_attribute_maps = {\"sex\": {1.0: 'Male', 0.0: 'Female'}}\n",
    "\n",
    "    return AdultDataset(\n",
    "        label_name=Y_features[0],\n",
    "        favorable_classes=['>50K', '>50K.'],\n",
    "        protected_attribute_names=D_features,\n",
    "        privileged_classes=[all_privileged_classes[x] for x in D_features],\n",
    "        instance_weights_name=None,\n",
    "        categorical_features=categorical_features,\n",
    "        features_to_keep=X_features + Y_features + D_features,\n",
    "        na_values=['?'],\n",
    "        metadata={'label_maps': [{1.0: '>50K', 0.0: '<=50K'}],\n",
    "                  'protected_attribute_maps': [all_protected_attribute_maps[x]\n",
    "                                               for x in D_features]},\n",
    "        custom_preprocessing=custom_preprocessing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weird-sight",
   "metadata": {},
   "source": [
    "The code below is to load the data and run the fairness fixing algorithm proposed by Calmon et al. \\[1\\]. We set missing values as a new category in features containing missing values. <br>\n",
    "Note that we modified the distortion function at ```get_distortion_adult```. In this function, we define the penalty for the fairness fixing algorithm to change values in each feature. In this distortion function, we set penalty to be 0 if the original observation value changes from the missing category to a non-missing category and we set a big penalty if the original value changes from a non-missing category to the missing category or the original values remain at the missing category. <br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "victorian-adult",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values\n",
      "6817\n",
      "Total number of observations\n",
      "48842\n",
      "Optimized Preprocessing: Objective converged to 0.124961\n"
     ]
    }
   ],
   "source": [
    "privileged_groups = [{'sex': 1}]\n",
    "unprivileged_groups = [{'sex': 0}]\n",
    "dataset_orig = load_preproc_data_adult(['sex'])\n",
    "\n",
    "optim_options = {\n",
    "    \"distortion_fun\": get_distortion_adult,\n",
    "    \"epsilon\": 0.02,\n",
    "    \"clist\": [0.99, 1.99, 2.99],\n",
    "    \"dlist\": [.1, 0.05, 0]\n",
    "}\n",
    "\n",
    "dataset_orig_train, dataset_orig_vt = dataset_orig.split(\n",
    "    [0.7], shuffle=True)\n",
    "\n",
    "OP = OptimPreproc(OptTools, optim_options,\n",
    "                  unprivileged_groups=unprivileged_groups,\n",
    "                  privileged_groups=privileged_groups)\n",
    "\n",
    "OP = OP.fit(dataset_orig_train)\n",
    "\n",
    "dataset_transf_cat_test = OP.transform(dataset_orig_vt, transform_Y=True)\n",
    "dataset_transf_cat_test = dataset_orig_vt.align_datasets(\n",
    "    dataset_transf_cat_test)\n",
    "\n",
    "dataset_transf_cat_train = OP.transform(\n",
    "    dataset_orig_train, transform_Y=True)\n",
    "dataset_transf_cat_train = dataset_orig_train.align_datasets(\n",
    "    dataset_transf_cat_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "judicial-island",
   "metadata": {},
   "source": [
    "In this part we use the training data obtained from the fairness fixing algorithm by Calmon et al. \\[1\\] to train a logistic regression classifier and validate the classifier on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "transsexual-bleeding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without reweight\n",
      "Accuracy\n",
      "0.7601856275165495\n",
      "p-rule\n",
      "0.6191770420783865\n",
      "FPR for unpriv group\n",
      "0.14370982552800737\n",
      "FNR for unpriv group\n",
      "0.6374745417515275\n",
      "FPR for priv group\n",
      "0.16569851873366248\n",
      "FNR for priv group\n",
      "0.4910958904109589\n"
     ]
    }
   ],
   "source": [
    "scale_transf = StandardScaler()\n",
    "X_train = scale_transf.fit_transform(dataset_transf_cat_train.features)\n",
    "y_train = dataset_transf_cat_train.labels.ravel()\n",
    "X_test = scale_transf.fit_transform(dataset_transf_cat_test.features)\n",
    "\n",
    "lmod = LogisticRegression()\n",
    "lmod.fit(X_train, y_train)\n",
    "y_pred = lmod.predict(X_test)\n",
    "print('Without reweight')\n",
    "get_evaluation(dataset_orig_vt,y_pred,privileged_groups,unprivileged_groups,0,1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detailed-raising",
   "metadata": {},
   "source": [
    "After getting the accuracy and fairness results, we apply our reweighting algorithm to train a new logistic regression classifier and validate the classifier on the same test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "wooden-captain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With reweight\n",
      "Accuracy\n",
      "0.7506995154575855\n",
      "p-rule\n",
      "0.7662700956069585\n",
      "FPR for unpriv group\n",
      "0.18158861340679522\n",
      "FNR for unpriv group\n",
      "0.584521384928717\n",
      "FPR for priv group\n",
      "0.16569851873366248\n",
      "FNR for priv group\n",
      "0.4910958904109589\n"
     ]
    }
   ],
   "source": [
    "dataset_orig_train.instance_weights = reweight_df(dataset_orig_train)\n",
    "scale_transf = StandardScaler()\n",
    "X_train = scale_transf.fit_transform(dataset_transf_cat_train.features)\n",
    "y_train = dataset_transf_cat_train.labels.ravel()\n",
    "\n",
    "X_test = scale_transf.fit_transform(dataset_transf_cat_test.features)\n",
    "\n",
    "lmod = LogisticRegression()\n",
    "lmod.fit(X_train, y_train, sample_weight=dataset_orig_train.instance_weights)\n",
    "y_pred = lmod.predict(X_test)\n",
    "print('With reweight')\n",
    "get_evaluation(dataset_orig_vt,y_pred,privileged_groups,unprivileged_groups,0,1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sweet-bulletin",
   "metadata": {},
   "source": [
    "By comparing the two results, the fairness scores increase with a small tradeoff in accuracy (about 1\\% decrease in accuracy) <br>\n",
    "The code below process data and create missing values with MAR missing type. <br>\n",
    "The function below process data and create missing values in the dataset. In the function below, the missing value mechanism is MAR that the missing values do not depend on the feature itself.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "japanese-instrument",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preproc_data_adult(protected_attributes=None):\n",
    "    def custom_preprocessing(df):\n",
    "        \"\"\"The custom pre-processing function is adapted from\n",
    "            https://github.com/fair-preprocessing/nips2017/blob/master/Adult/code/Generate_Adult_Data.ipynb\n",
    "        \"\"\"\n",
    "        np.random.seed(1)\n",
    "        # Group age by decade\n",
    "        df['Age (decade)'] = df['age'].apply(lambda x: x // 10 * 10)\n",
    "        def group_edu(x):\n",
    "            if x == -1:\n",
    "                return 'missing_edu'\n",
    "            elif x <= 5:\n",
    "                return '<6'\n",
    "            elif x >= 13:\n",
    "                return '>12'\n",
    "            else:\n",
    "                return x\n",
    "\n",
    "        def age_cut(x):\n",
    "            if x >= 70:\n",
    "                return '>=70'\n",
    "            else:\n",
    "                return x\n",
    "\n",
    "        def group_race(x):\n",
    "            if x == \"White\":\n",
    "                return 1.0\n",
    "            else:\n",
    "                return 0.0\n",
    "\n",
    "        # Cluster education and age attributes.\n",
    "        # Limit education range\n",
    "        df['Education Years'] = df['education-num'].apply(\n",
    "            lambda x: group_edu(x))\n",
    "        df['Education Years'] = df['Education Years'].astype('category')\n",
    "\n",
    "        # Limit age range\n",
    "        df['Age (decade)'] = df['Age (decade)'].apply(lambda x: age_cut(x))\n",
    "\n",
    "        # Rename income variable\n",
    "        df['Income Binary'] = df['income-per-year']\n",
    "\n",
    "        # Recode sex and race\n",
    "        df['sex'] = df['sex'].replace({'Female': 0.0, 'Male': 1.0})\n",
    "        df['race'] = df['race'].apply(lambda x: group_race(x))\n",
    "        \n",
    "        # Here we define a column called mis_prob to assign the probability of each observation \n",
    "        # being missed\n",
    "        df['mis_prob'] = 0\n",
    "        for index, row in df.iterrows():\n",
    "            # Here, the probability of missing values in Education Years depends on sex and \n",
    "            # Income Binary, so in this case the missing values are under MAR because the missingness \n",
    "            # does not depend on the feature Education Years\n",
    "            # To change the distribution of missing values, we can change the probability here\n",
    "            if row['sex']==0 and row['Income Binary'] =='>50K':\n",
    "                df.loc[index,'mis_prob'] = 0.4\n",
    "            elif row['sex']==0:\n",
    "                df.loc[index,'mis_prob'] = 0.1\n",
    "            else:\n",
    "                df.loc[index,'mis_prob'] = 0.05\n",
    "        new_label = []\n",
    "        for index, row in df.iterrows():\n",
    "            if np.random.binomial(1, float(row['mis_prob']), 1)[0] == 1:\n",
    "                new_label.append('missing_edu')\n",
    "            else:\n",
    "                new_label.append(row['Education Years'])\n",
    "                \n",
    "        df['Education Years'] = new_label\n",
    "        print('Total number of missing values')\n",
    "        print(len(df.loc[df['Education Years'] == 'missing_edu', :].index))\n",
    "        print('Total number of observations')\n",
    "        print(len(df.index))\n",
    "        return df\n",
    "    XD_features = ['Age (decade)', 'Education Years', 'sex']\n",
    "    D_features = [\n",
    "        'sex'] if protected_attributes is None else protected_attributes\n",
    "    Y_features = ['Income Binary']\n",
    "    X_features = list(set(XD_features) - set(D_features))\n",
    "    categorical_features = ['Age (decade)', 'Education Years']\n",
    "\n",
    "    # privileged classes\n",
    "    all_privileged_classes = {\"sex\": [1.0]}\n",
    "\n",
    "    # protected attribute maps\n",
    "    all_protected_attribute_maps = {\"sex\": {1.0: 'Male', 0.0: 'Female'}}\n",
    "\n",
    "    return AdultDataset(\n",
    "        label_name=Y_features[0],\n",
    "        favorable_classes=['>50K', '>50K.'],\n",
    "        protected_attribute_names=D_features,\n",
    "        privileged_classes=[all_privileged_classes[x] for x in D_features],\n",
    "        instance_weights_name=None,\n",
    "        categorical_features=categorical_features,\n",
    "        features_to_keep=X_features + Y_features + D_features,\n",
    "        na_values=['?'],\n",
    "        metadata={'label_maps': [{1.0: '>50K', 0.0: '<=50K'}],\n",
    "                  'protected_attribute_maps': [all_protected_attribute_maps[x]\n",
    "                                               for x in D_features]},\n",
    "        custom_preprocessing=custom_preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resident-apparatus",
   "metadata": {},
   "source": [
    "Same as above, we load the data and run the fairness fixing algorithm proposed by Calmon et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "attempted-auditor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of missing values\n",
      "3580\n",
      "Total number of observations\n",
      "48842\n",
      "Optimized Preprocessing: Objective converged to 0.065679\n"
     ]
    }
   ],
   "source": [
    "privileged_groups = [{'sex': 1}]\n",
    "unprivileged_groups = [{'sex': 0}]\n",
    "dataset_orig = load_preproc_data_adult(['sex'])\n",
    "\n",
    "optim_options = {\n",
    "    \"distortion_fun\": get_distortion_adult,\n",
    "    \"epsilon\": 0.03,\n",
    "    \"clist\": [0.99, 1.99, 2.99],\n",
    "    \"dlist\": [.1, 0.05, 0]\n",
    "}\n",
    "\n",
    "dataset_orig_train, dataset_orig_vt = dataset_orig.split(\n",
    "    [0.7], shuffle=True)\n",
    "\n",
    "OP = OptimPreproc(OptTools, optim_options,\n",
    "                  unprivileged_groups=unprivileged_groups,\n",
    "                  privileged_groups=privileged_groups)\n",
    "\n",
    "OP = OP.fit(dataset_orig_train)\n",
    "\n",
    "dataset_transf_cat_test = OP.transform(dataset_orig_vt, transform_Y=True)\n",
    "dataset_transf_cat_test = dataset_orig_vt.align_datasets(\n",
    "    dataset_transf_cat_test)\n",
    "\n",
    "dataset_transf_cat_train = OP.transform(\n",
    "    dataset_orig_train, transform_Y=True)\n",
    "dataset_transf_cat_train = dataset_orig_train.align_datasets(\n",
    "    dataset_transf_cat_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "victorian-corruption",
   "metadata": {},
   "source": [
    "Same as MNAR case, we first train a logistic regression classifier without reweight and train another logistic regression classifier with reweight and validate both of them on the same test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "mysterious-clear",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without reweight\n",
      "Accuracy\n",
      "0.7677608680816215\n",
      "p-rule\n",
      "0.6894999359511296\n",
      "FPR for unpriv group\n",
      "0.1480716253443526\n",
      "FNR for unpriv group\n",
      "0.5193482688391038\n",
      "FPR for priv group\n",
      "0.15742085390647687\n",
      "FNR for priv group\n",
      "0.4859589041095891\n"
     ]
    }
   ],
   "source": [
    "scale_transf = StandardScaler()\n",
    "X_train = scale_transf.fit_transform(dataset_transf_cat_train.features)\n",
    "y_train = dataset_transf_cat_train.labels.ravel()\n",
    "X_test = scale_transf.fit_transform(dataset_transf_cat_test.features)\n",
    "\n",
    "lmod = LogisticRegression()\n",
    "lmod.fit(X_train, y_train)\n",
    "y_pred = lmod.predict(X_test)\n",
    "print('Without reweight')\n",
    "get_evaluation(dataset_orig_vt,y_pred,privileged_groups,unprivileged_groups,0,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "advanced-nomination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With reweight\n",
      "Accuracy\n",
      "0.762778953115403\n",
      "p-rule\n",
      "0.7773321284771667\n",
      "FPR for unpriv group\n",
      "0.16896235078053257\n",
      "FNR for unpriv group\n",
      "0.484725050916497\n",
      "FPR for priv group\n",
      "0.1565495207667732\n",
      "FNR for priv group\n",
      "0.4876712328767123\n"
     ]
    }
   ],
   "source": [
    "dataset_orig_train.instance_weights = reweight_df(dataset_orig_train)\n",
    "scale_transf = StandardScaler()\n",
    "X_train = scale_transf.fit_transform(dataset_transf_cat_train.features)\n",
    "y_train = dataset_transf_cat_train.labels.ravel()\n",
    "X_test = scale_transf.fit_transform(dataset_transf_cat_test.features)\n",
    "lmod = LogisticRegression()\n",
    "lmod.fit(X_train, y_train, sample_weight=dataset_orig_train.instance_weights)\n",
    "y_pred = lmod.predict(X_test)\n",
    "print('With reweight')\n",
    "get_evaluation(dataset_orig_vt,y_pred,privileged_groups,unprivileged_groups,0,1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breeding-egypt",
   "metadata": {},
   "source": [
    "Similar to results from MNAR, our reweighting algorithm improves the fairness scores with a small tradeoff in accuracy. <br>\n",
    "# Reference\n",
    "[1] Optimized Pre-Processing for Discrimination Prevention <br>\n",
    "Flavio Calmon, Dennis Wei, Bhanukiran Vinzamuri, Karthikeyan Natesan Ramamurthy and Kush R. Varshney.\n",
    "31st Advances in Neural Information Processing Systems (NIPS), Long Beach, CA, December 2017."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
